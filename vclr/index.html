<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="v-CLR: Learning Appearance-Invariant Representation for Open-Wolrd Instance Segmentation">
  <meta name="keywords" content="open-world instance segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>v-CLR: Learning Appearance-Invariant Representation for Open-World Instance Segmentation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/visailab.jpeg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script type="text/javascript" src="./static/js/copy.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- MathJax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="font-size: 3.5rem;"><em>v</em>-CLR: Learning Appearance-Invariant Representation for Open-World Instance Segmentation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zhangchbin.github.io">Chang-Bin Zhang</a><sup>1</sup>,</span>
              <span class="author-block">
                Jinhong Ni<sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://y-zhong.info">Yujie Zhong</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.kaihan.org/">Kai Han</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Visual AI Lab, The University of Hong Kong</span>
            <br>
            <span class="author-block"><sup>2</sup>Meituan Inc.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- HuggingFace Demo Link -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-robot"></i>
                  </span>
                  <span>HF Demo</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Visual-AI/vCLR"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="#Bib"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>BibTex</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- motivation -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Motivation</h2>
        <h2 class="title is-5" style="color: rgb(221, 149, 17);">We propose a training framework, View-Consistent LeaRning (<em>v</em>-CLR), which aims to encourage
        the model to learn appearance-invariant representations for class-generalizable instance segmentation.</h2>
        <p style="text-align: left;">
          On the CLEVR dataset, we train the model using the red-metal class,
          designated as the known class.
          We then evaluate its performance on novel classes with disjoint attributes.
          This toy example illustrates that incorporating colorized depth images into the training set enhances the model's generalization ability, enabling it to better detect novel objects.
          <!-- On CLEVR dataset, the model is trained with red-metal class, which is regarded as the known class.
          Then we evaluate the model on novel classes with disjoint attributes.
          This toy example demonstrates that, when we incorporating colorized depth images into training set, 
          the model shows stronger generalization ability on discovering novel objects. -->
        </p>
        <img src="src/motivation.png" alt="Motivation Image" style="width:100%; height:auto; margin-top:20px;">
      </div>
    </div>
  </div>
</section>




<!-- Image Carousel Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Qualitative Results</h2>
        <h2 class="title is-5">The model is trained on the COCO2017 with 20 VOC classes.<br>Top-10 predictions are shown in each image.</h2>
        <div class="image-carousel" style="position: relative; display: inline-block; width: 100%;">
          <button class="carousel-button prev" onclick="prevImage()"></button>
          <img id="carousel-image" src="resources/Picture1.png" alt="Image 1" style="width:100%; height:auto;">
          <button class="carousel-button next" onclick="nextImage()"></button>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  .carousel-button {
    position: absolute;
    top: 50%;
    transform: translateY(-50%);
    width: 0;
    height: 0;
    border-style: solid;
    opacity: 0.7;
    cursor: pointer;
    background: transparent;
  }

  .prev {
    left: -60px;
    border-width: 15px 20px 15px 0;
    border-color: transparent #000 transparent transparent;
  }

  .next {
    right: -60px;
    border-width: 15px 0 15px 20px;
    border-color: transparent transparent transparent #000;
  }

  .carousel-button:hover {
    opacity: 1;
  }

  .publication-title {
    text-align: center;
    font-style: normal;
  }
</style>

<script>
  const images = [
    'src/Picture1.png',
    'src/Picture2.png',
    'src/Picture3.png',
    'src/Picture4.png',
    'src/Picture5.png',
    'src/Picture6.png',
    'src/Picture7.png',
    'src/Picture8.png',
    'src/Picture9.png',
  ];
  let currentIndex = 0;

  function showImage(index) {
    const imgElement = document.getElementById('carousel-image');
    imgElement.src = images[index];
  }

  function prevImage() {
    currentIndex = (currentIndex > 0) ? currentIndex - 1 : images.length - 1;
    showImage(currentIndex);
  }

  function nextImage() {
    currentIndex = (currentIndex < images.length - 1) ? currentIndex + 1 : 0;
    showImage(currentIndex);
  }

  // Initialize the carousel with the first image
  showImage(currentIndex);
</script>

<!-- Method Section -->
<section class="section" id="Method">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Method</h2>
        <p>
          Our learning framework consists of two branches, the natural image branch (top) and the transformed
          image branch (bottom). Both branches adopt transformers to make predictions, which are then matched with the object proposals to obtain
          optimized object queries. We compute a matching loss \( L_{\text{match}} \) which enforces the matched object-oriented query pairs from the two
          branches to be similar. We finally compute the ordinary segmentation loss \( L_{\text{gt}} \) using the ground truth labels. The transformer in the natural
          image branch is updated as an EMA model of the transformed image branch. In our method, we utilize the unsupervised pretrained CutLER to provide the general object proposals, which ensures no potential information leakage in our method.
        </p>
        <img src="src/method.png" alt="Method Image" style="width:100%; height:auto; margin-top:20px;">
      </div>
    </div>
  </div>
</section>

<!-- Experiments Section -->
<section class="section" id="Experiments">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Experiments</h2>
        <div class="columns is-multiline">
          <div class="column is-half">
            <img src="src/table1.png" alt="Table 1" style="width:100%; height:auto; margin-top:20px;">
          </div>
          <div class="column is-half">
            <img src="src/table2.png" alt="Table 2" style="width:100%; height:auto; margin-top:20px;">
          </div>
          <div class="column is-half">
            <img src="src/table3.png" alt="Table 3" style="width:100%; height:auto; margin-top:20px;">
          </div>
          <div class="column is-half">
            <img src="src/table4.png" alt="Table 4" style="width:100%; height:auto; margin-top:20px;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- existing BibTeX section -->
<section class="section" id="Bib">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code id="BibTeX">@inproceedings{zhang2024vclr,
      title={v-CLR: Learning Appearance-Invariant Representation for Open-World Instance Segmentation},
      author={Zhang, Chang-Bin and Ni, Jinhong and Zhong, Yujie and Han, Kai},
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
      year={2025}
    }
    </code><button class="copy-button" style="--button-hover-background: var(--example-color-alt); --button-color: var(--white); --button-background: var(--example-color-alt); --button-margin-bottom: 0;" class="copyButton btn" onclick="copyToClipboard('BibTeX','BibTeX_cop')"><i class="fa fa-copy"></i></button><p id="BibTeX_cop" style="display:none;color: #a0a0a0">Copied!</p></pre>
  </div>
</section>


  <section class="section" id="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
          <center>
            This website is based on <a href="https://nerfies.github.io/">Nerfies</a>.
          </center>
          </p>
        </div>
      </div>
    </div>
  </div>
 </section>


</body>
</html>
